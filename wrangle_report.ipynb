{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Report for WeRateDogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"## Introduction\">Introduction</a></li>\n",
    "<li><a href=\"## Step 1: Gathering Data\">Step 1: Gathering Data</a></li>\n",
    "<li><a href=\"## Step 2: Assessing Data\">Step 2: Assessing Data</a></li>\n",
    "<li><a href=\"## Step 3: Cleaning Data\">Step3: Cleaning Data</a></li>\n",
    "<li><a href=\"## Further Steps\">Further Steps</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report is to document the the data wrangling I undertook as part of the Wrangling and Analyze Data project for the Udacity Data Analysis Nanodegree. The data we wrangled was from the a twitter archive called WeRateDogs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a number of data sources in this first step, some supplied as part of the project while the rest I queried.\n",
    "\n",
    " - Twitter Archive Data: A csv file supplied as part of the project and downloaded (from: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv).\n",
    " - Tweet Image Predictions: a tsv file programatically downloaded from https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv which includes the dog breed predictions along with links to the jpg.\n",
    " - API & JSON: After creating a twitter account, and gaining developer access (which was a painful experience when dealing with the analyst processing the request!) I was able to use Twitter API. Using the provided key, token & secrets I extracted tweet_id, retweet_count & favorite_count the latter two as integers. This pulled data used the Tweet IDs from the Archive Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage I did both manual assessments & programatic assessments of the data. The manual assessments I did both within the workspace & within excel for both quality & tidiness issues.\n",
    "\n",
    "Below I will go over the Quality & Tidiness I uncovered for each of the Data Sources we used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter Archive Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We can see the NaN value (indicating blanks) repeatedly show up in the following columns: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded urls\n",
    " - Some of the rating denominators are not 10. After manually going through these and filtering out replies and retweets we can see 5 that need fixed and 1 that needs deleted for lacking a rating at all.\n",
    "  - Fix: After so many requests, this is Bretagne. She was the last surviving 9/11 search dog, and our second ever 14/10. RIP https://t.co/XAVDNDaVgQ\n",
    "  - Fix: Happy 4/20 from the squad! 13/10 for all https://t.co/eV1diwds8a\n",
    "  - Fix: This is Bluebert. He just saw that both #FinalFur match ups are split 50/50. Amazed af. 11/10 https://t.co/Kky1DPG4iq\n",
    "  - Fix: This is Darrel. He just robbed a 7/11 and is in a high speed police chase. Was just spotted by the helicopter 10/10 https://t.co/7EsP8LmSp5\n",
    "  - Fix: This is an Albanian 3 1/2 legged  Episcopalian. Loves well-polished hardwood flooring. Penis on the collar. 9/10 https://t.co/d9NcXFKwLv\n",
    "  - Delete: Meet Sam. She smiles 24/7 &amp; secretly aspires to be a reindeer.\n",
    " - A lot of the entries under the name column are not correct, the most predominate \"None\" & \"a\".\n",
    " - Tweet_id should be a string but is currently an integer.\n",
    " - The Timestamp is in object (string) format and should be in datetime format.\n",
    " - 181 lines of data need to be removed as they have a valid retweeted_status_user_id showing they're retweets.\n",
    " - 78 lines also need to be removed as they have a valid in_reply_to_status_id showing they're replies.\n",
    " - Multiple dog \"stage\" (doggo, floffer, pupper, puppo) columns aren't needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Again Tweet_id should be a string but is currently an integer.\n",
    " - Multiple predictions for dog type/breed are in each tweet, we don't need more than 1 prediction.\n",
    " - Some of the predictions aren't valid dog breeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweet JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - No issues, we already have our counts as integers due to the earlier mentioned part in Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The three datasets need merged into a cleaned master file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I undertook the following steps to Clean the Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All\n",
    " - Made copies of each of the datasets.\n",
    " - Merged into a Masterfile.\n",
    " \n",
    "#### Twitter Archive Data\n",
    " - Removed the 181 retweets.\n",
    " - Removed the 78 replies.\n",
    " - Converted the Timestamp from object to datetime format.\n",
    " - Converted Tweet_id from an integer to a string.\n",
    " - Manually fixed the 5 with incorrect ratings based on their text.\n",
    " - Deleted the entry with no score.\n",
    " - Created a new rating column based on the rating_numenator & rating_denominator. This should tidy up the non-10 valid denominators.\n",
    "\n",
    "#### Predictions\n",
    " - Converted Tweet_id from an integer to a string.\n",
    " - Droped extra dog predictions, we only need p1 not p2 & p3.\n",
    " - Droped non-dog predictions.\n",
    "\n",
    "#### Tweet Json\n",
    " - None.\n",
    " \n",
    "#### All\n",
    " - Made copies of each of the datasets.\n",
    " - Merged into a Masterfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here on we are no longer doing Data Wrangling but working on the twitter_archive_master.csv dataset to draw insights and create useful visualisations for the WeRateDogs Twitter Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook wrangle_report.ipynb to pdf\n",
      "[NbConvertApp] Writing 21932 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 29632 bytes to wrangle_report.pdf\n"
     ]
    }
   ],
   "source": [
    "#### Convert to PDF\n",
    "!jupyter nbconvert --to pdf wrangle_report.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
